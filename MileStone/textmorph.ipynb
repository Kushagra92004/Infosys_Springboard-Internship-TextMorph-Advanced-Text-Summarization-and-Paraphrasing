{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Day 4 : Mastering Summarization & Paraphrasing\n",
        "Welcome to today's intensive session. We're moving beyond basic implementation to truly understand and control the AI models that power TextMorph. You'll see how they handle diverse texts and learn to tune their parameters like a pro.\n",
        "\n",
        "## Today's Agenda:\n",
        "## Part 1: The Art of Summarization:\n",
        "\n",
        "Detailed explanation of Abstractive vs. Extractive summarization.\n",
        "\n",
        "Code examples with technical, business, and creative texts.\n",
        "\n",
        "An interactive \"Summarizer Studio\" to experiment with your own text.\n",
        "\n",
        "In-depth guide to tuning parameters.\n",
        "\n",
        "## Part 2: The Craft of Paraphrasing:\n",
        "\n",
        "Practical use-cases for paraphrasing.\n",
        "\n",
        "Code examples with formal, casual, and marketing language.\n",
        "\n",
        "An interactive \"Paraphraser Playground\" to rephrase any sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "DTrm9522q32A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 0: Session Setup\n",
        "Let's get our environment ready by installing and importing the necessary libraries."
      ],
      "metadata": {
        "id": "oc00FxNZq7vO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-wvox98qyKD",
        "outputId": "3a9642b2-c3de-4645-b4ea-5bf34aa968fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries installed.\n",
            "‚úÖ Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "#@title 0.1: Install and Import Libraries\n",
        "# Install the required libraries quietly.\n",
        "!pip install transformers sentencepiece --quiet\n",
        "print(\"‚úÖ Libraries installed.\")\n",
        "\n",
        "# Import the necessary classes from the transformers library.\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "# 'textwrap' is a great tool for formatting our output nicely.\n",
        "import textwrap\n",
        "print(\"‚úÖ Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1: The Art of Summarization\n",
        "### Section 1.1: What is Abstractive Summarization?\n",
        "Before we code, let's understand the magic. Imagine you have a pile of Lego bricks (the words in an article).\n",
        "\n",
        "Extractive Summarization: This is like picking the most important-looking Lego bricks and presenting them as the summary. It selects key sentences directly from the original text. It's fast and factually accurate but can sound robotic.\n",
        "\n",
        "Abstractive Summarization: This is like looking at the Lego pile, understanding the idea (e.g., \"it's a car\"), and then building a smaller, new car using your own Lego bricks. Our T5 model works this way‚Äîit reads the text, understands the core concepts, and then generates new, human-like sentences to form a summary. This is more advanced and leads to more fluent results."
      ],
      "metadata": {
        "id": "UaqeWO1IrNeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.2: Loading Our T5 Summarization Model\n",
        "We'll use t5-base, a powerful and well-balanced version of Google's T5 model. It's a great starting point for high-quality summarization."
      ],
      "metadata": {
        "id": "cJIHwvebrP99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2: Load the T5 Model and Tokenizer\n",
        "# The model name we'll be using.\n",
        "t5_model_name = 't5-base'\n",
        "\n",
        "# The Tokenizer is responsible for converting text into a format the model understands.\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "\n",
        "# The Model is the pre-trained AI that performs the summarization.\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
        "\n",
        "print(f\"‚úÖ T5 Model ('{t5_model_name}') is loaded and ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4dvu3oLrbPD",
        "outputId": "4e16dda1-6e85-4e9e-fa99-d982f3c0be98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T5 Model ('t5-base') is loaded and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.3: The Summarizer Function\n",
        "This is our core function. We're adding a new parameter, no_repeat_ngram_size, to prevent the model from repeating the same phrases."
      ],
      "metadata": {
        "id": "RY0-wYwurl3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3: Define the Core Summarizer Function\n",
        "def generate_summary(text, min_len=40, max_len=120, beams=4):\n",
        "    \"\"\"\n",
        "    Generates a high-quality abstractive summary for a given text using the T5 model.\n",
        "    \"\"\"\n",
        "    # T5 models require a \"summarize: \" prefix to know which task to perform.\n",
        "    input_text = \"summarize: \" + text.strip().replace(\"\\n\", \" \")\n",
        "\n",
        "    # Tokenize the text, ensuring it's not too long for the model.\n",
        "    inputs = t5_tokenizer.encode(input_text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate the summary using our specified parameters.\n",
        "    summary_ids = t5_model.generate(\n",
        "        inputs,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        num_beams=beams,\n",
        "        no_repeat_ngram_size=3, # Prevents repeating phrases of 3 words.\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the result back into human-readable text.\n",
        "    summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "YBHP7QMDroLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.4: Code Examples with Diverse Texts\n",
        "Let's test our summarizer on different styles of writing to see how it performs."
      ],
      "metadata": {
        "id": "7TIIS-hCrrJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4.1: Example 1 - Technical Text (Quantum Computing)\n",
        "technical_text = \"\"\"\n",
        "Quantum computing is a revolutionary type of computation that harnesses the collective properties of quantum states,\n",
        "such as superposition and entanglement, to perform calculations. While classical computers use bits that can be either\n",
        "a 0 or a 1, a quantum computer uses qubits, which can be a 0, a 1, or both at the same time. This fundamental difference\n",
        "allows quantum computers to solve complex problems that are intractable for even the most powerful classical supercomputers,\n",
        "with potential applications in cryptography, materials science, and drug discovery.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(technical_text, min_len=25, max_len=50)\n",
        "\n",
        "print(\"----------- TECHNICAL TEXT -----------\")\n",
        "print(textwrap.fill(technical_text, width=100))\n",
        "print(\"\\n‚ú®---------- T5 SUMMARY -----------‚ú®\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlY39-otrsL_",
        "outputId": "a81e98bd-d7a7-4271-d2de-a9b58ad9d361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- TECHNICAL TEXT -----------\n",
            " Quantum computing is a revolutionary type of computation that harnesses the collective properties\n",
            "of quantum states, such as superposition and entanglement, to perform calculations. While classical\n",
            "computers use bits that can be either a 0 or a 1, a quantum computer uses qubits, which can be a 0,\n",
            "a 1, or both at the same time. This fundamental difference allows quantum computers to solve complex\n",
            "problems that are intractable for even the most powerful classical supercomputers, with potential\n",
            "applications in cryptography, materials science, and drug discovery.\n",
            "\n",
            "‚ú®---------- T5 SUMMARY -----------‚ú®\n",
            "quantum computing is a revolutionary type of computation that harnesses quantum states . a quantum\n",
            "computer uses qubits, which can be a 0, a 1, or both at the same time . quantum computers can solve\n",
            "complex problems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4.2: Example 2 - Business Text (Market Analysis)\n",
        "business_text = \"\"\"\n",
        "The global market for renewable energy is projected to experience robust growth over the next decade. Key drivers include\n",
        "increasing government incentives for clean energy, declining costs of solar and wind technologies, and growing consumer\n",
        "awareness regarding climate change. However, challenges remain, such as the intermittency of renewable sources and the\n",
        "need for significant grid infrastructure upgrades. Companies that can innovate in energy storage solutions and grid\n",
        "management are best positioned to capitalize on this market trend.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(business_text, min_len=30, max_len=90)\n",
        "\n",
        "print(\"----------- BUSINESS TEXT -----------\")\n",
        "print(textwrap.fill(business_text, width=100))\n",
        "print(\"\\n‚ú®---------- T5 SUMMARY -----------‚ú®\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP1O3t4Mr0k7",
        "outputId": "30188a8e-1630-4940-9dd6-97b4daf53f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- BUSINESS TEXT -----------\n",
            " The global market for renewable energy is projected to experience robust growth over the next\n",
            "decade. Key drivers include increasing government incentives for clean energy, declining costs of\n",
            "solar and wind technologies, and growing consumer awareness regarding climate change. However,\n",
            "challenges remain, such as the intermittency of renewable sources and the need for significant grid\n",
            "infrastructure upgrades. Companies that can innovate in energy storage solutions and grid management\n",
            "are best positioned to capitalize on this market trend.\n",
            "\n",
            "‚ú®---------- T5 SUMMARY -----------‚ú®\n",
            "the global market for renewable energy is projected to experience robust growth over the next decade\n",
            ". key drivers include increasing government incentives for clean energy . challenges remain, such as\n",
            "the intermittency of renewable sources and the need for significant grid upgrades .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4.3: Example 3 - Creative Text (Literary Description)\n",
        "creative_text = \"\"\"\n",
        "The ancient library was a labyrinth of shadows and whispered knowledge. Sunlight struggled through a high,\n",
        "arched window, illuminating motes of dust that danced like tiny sprites in the golden shafts of light.\n",
        "The air smelled of aging paper, leather, and a faint, sweet hint of vanilla. Every towering bookshelf\n",
        "was a gateway to another world, each leather-bound volume a silent promise of adventure, history,\n",
        "or forgotten magic. It was a place where time itself seemed to slow down, holding its breath in reverence\n",
        "for the stories it contained.\n",
        "\"\"\"\n",
        "\n",
        "summary = generate_summary(creative_text, min_len=20, max_len=70)\n",
        "\n",
        "print(\"----------- CREATIVE TEXT -----------\")\n",
        "print(textwrap.fill(creative_text, width=100))\n",
        "print(\"\\n‚ú®---------- T5 SUMMARY -----------‚ú®\")\n",
        "print(textwrap.fill(summary, width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA8SZFWHr1z0",
        "outputId": "8ae12224-cef4-4dd5-fc63-8e63c8b0b56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- CREATIVE TEXT -----------\n",
            " The ancient library was a labyrinth of shadows and whispered knowledge. Sunlight struggled through\n",
            "a high, arched window, illuminating motes of dust that danced like tiny sprites in the golden shafts\n",
            "of light. The air smelled of aging paper, leather, and a faint, sweet hint of vanilla. Every\n",
            "towering bookshelf was a gateway to another world, each leather-bound volume a silent promise of\n",
            "adventure, history, or forgotten magic. It was a place where time itself seemed to slow down,\n",
            "holding its breath in reverence for the stories it contained.\n",
            "\n",
            "‚ú®---------- T5 SUMMARY -----------‚ú®\n",
            "the ancient library was a labyrinth of shadows and whispered knowledge . each leather-bound volume a\n",
            "silent promise of adventure, history, or forgotten magic . a place where time itself seemed to slow\n",
            "down in reverence for the stories it contained .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1.5: The Interactive Summarizer Studio\n",
        "Now it's your turn! Paste your own text, experiment with the settings, and see how you can craft the perfect summary."
      ],
      "metadata": {
        "id": "hk9L0LrpsAis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.5: Your Interactive Summarizer Studio! ‚ö°Ô∏è\n",
        "#@markdown ### üëà Paste your text below and tune the parameters!\n",
        "input_text = 'The James Webb Space Telescope (JWST) is a space telescope designed primarily to conduct infrared astronomy. As the largest optical telescope in space, its high resolution and sensitivity allow it to view objects too old, distant, or faint for the Hubble Space Telescope. This has enabled investigations in many fields of astronomy and cosmology, such as observation of the first stars, the formation of the first galaxies, and detailed atmospheric characterization of potentially habitable exoplanets. The U.S. National Aeronautics and Space Administration (NASA) led JWST\\'s development in collaboration with the European Space Agency (ESA) and the Canadian Space Agency (CSA).' #@param {type:\"string\"}\n",
        "min_length = 45 #@param {type:\"slider\", min:10, max:100, step:5}\n",
        "max_length = 140 #@param {type:\"slider\", min:50, max:200, step:10}\n",
        "num_beams = 5 #@param {type:\"slider\", min:2, max:8, step:1}\n",
        "\n",
        "# --- Run the summarizer with your settings ---\n",
        "generated_summary = generate_summary(input_text, min_len=min_length, max_len=max_length, beams=num_beams)\n",
        "\n",
        "# --- Display the results and analysis ---\n",
        "original_word_count = len(input_text.split())\n",
        "summary_word_count = len(generated_summary.split())\n",
        "reduction = 100 - (summary_word_count / original_word_count * 100)\n",
        "\n",
        "print(\"----------- YOUR INPUT TEXT -----------\")\n",
        "print(textwrap.fill(input_text, width=100))\n",
        "print(\"\\n‚ú®---------- GENERATED SUMMARY -----------‚ú®\")\n",
        "print(textwrap.fill(generated_summary, width=100))\n",
        "print(\"\\nüìä---------- ANALYSIS -----------üìä\")\n",
        "print(f\"Original Word Count: {original_word_count}\")\n",
        "print(f\"Summary Word Count: {summary_word_count}\")\n",
        "print(f\"Text Reduction: {reduction:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYi2rfyHsB8V",
        "outputId": "446c70bd-2921-4397-9d5e-73f33bd2a0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- YOUR INPUT TEXT -----------\n",
            "The James Webb Space Telescope (JWST) is a space telescope designed primarily to conduct infrared\n",
            "astronomy. As the largest optical telescope in space, its high resolution and sensitivity allow it\n",
            "to view objects too old, distant, or faint for the Hubble Space Telescope. This has enabled\n",
            "investigations in many fields of astronomy and cosmology, such as observation of the first stars,\n",
            "the formation of the first galaxies, and detailed atmospheric characterization of potentially\n",
            "habitable exoplanets. The U.S. National Aeronautics and Space Administration (NASA) led JWST's\n",
            "development in collaboration with the European Space Agency (ESA) and the Canadian Space Agency\n",
            "(CSA).\n",
            "\n",
            "‚ú®---------- GENERATED SUMMARY -----------‚ú®\n",
            "the James Webb Space Telescope (JWST) is the largest optical telescope in space . its high\n",
            "resolution and sensitivity allow it to view objects too old, distant, or faint . this has enabled\n",
            "investigations in many fields of astronomy and cosmology .\n",
            "\n",
            "üìä---------- ANALYSIS -----------üìä\n",
            "Original Word Count: 100\n",
            "Summary Word Count: 42\n",
            "Text Reduction: 58.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: The Craft of Paraphrasing\n",
        "### Section 2.1: Why is Paraphrasing Useful?\n",
        "Paraphrasing is more than just changing a few words. It's a powerful tool for:\n",
        "\n",
        "Improving Clarity: Rephrasing a complex sentence can make it easier to understand.\n",
        "\n",
        "Content Creation: Generating multiple versions of a marketing headline or social media post.\n",
        "\n",
        "Avoiding Plagiarism: Expressing someone else's idea in your own unique words (while still citing them!).\n",
        "\n",
        "Enhancing Writing: Finding more creative or engaging ways to say something."
      ],
      "metadata": {
        "id": "L_3a51lBsqXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.2: Loading Our PEGASUS Paraphrasing Model\n",
        "We'll use a PEGASUS model that has been specifically fine-tuned for the task of paraphrasing."
      ],
      "metadata": {
        "id": "AO_iulbssufr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2: Load the PEGASUS Model and Tokenizer\n",
        "paraphrase_model_name = 'tuner007/pegasus_paraphrase'\n",
        "\n",
        "pegasus_tokenizer = PegasusTokenizer.from_pretrained(paraphrase_model_name)\n",
        "pegasus_model = PegasusForConditionalGeneration.from_pretrained(paraphrase_model_name)\n",
        "\n",
        "print(f\"‚úÖ PEGASUS Model ('{paraphrase_model_name}') is loaded and ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHx807OAswKy",
        "outputId": "1a37d127-7914-43da-abfc-6b76e821aec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PEGASUS Model ('tuner007/pegasus_paraphrase') is loaded and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.3: The Paraphraser Function\n",
        "This function will take our input sentence and generate a list of high-quality alternatives.\n",
        "\n"
      ],
      "metadata": {
        "id": "44GIzYCotHVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3: Define the Core Paraphraser Function\n",
        "def generate_paraphrases(text, num_return=5, beams=10):\n",
        "    \"\"\"\n",
        "    Generates multiple high-quality paraphrases for a given text using the PEGASUS model.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text.\n",
        "    inputs = pegasus_tokenizer.encode(text, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate the paraphrases using beam search.\n",
        "    paraphrase_ids = pegasus_model.generate(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        num_beams=beams,\n",
        "        num_return_sequences=num_return,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the results back into text.\n",
        "    paraphrases = pegasus_tokenizer.batch_decode(paraphrase_ids, skip_special_tokens=True)\n",
        "    return paraphrases"
      ],
      "metadata": {
        "id": "aOrP0UGAtIz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.4: Code Examples with Diverse Sentences\n",
        "Let's see how PEGASUS handles different kinds of language."
      ],
      "metadata": {
        "id": "F3NCR6HFtZAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4.1: Example 1 - Formal / Academic Sentence\n",
        "formal_sentence = \"The empirical data indicates a statistically significant correlation between the two variables.\"\n",
        "paraphrases = generate_paraphrases(formal_sentence, num_return=4)\n",
        "\n",
        "print(f\"----------- ORIGINAL FORMAL SENTENCE -----------\\n'{formal_sentence}'\\n\")\n",
        "print(\"ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf5GrvdktaX-",
        "outputId": "88cf6d12-813e-4c78-88e1-4b665f749612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- ORIGINAL FORMAL SENTENCE -----------\n",
            "'The empirical data indicates a statistically significant correlation between the two variables.'\n",
            "\n",
            "ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\n",
            "  1. There is a statistically significant correlation between the two variables.\n",
            "  2. The data shows a statistically significant correlation between the two variables.\n",
            "  3. The empirical data shows a correlation between the two variables.\n",
            "  4. The data shows a correlation between the two variables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4.2: Example 2 - Casual / Idiomatic Sentence\n",
        "casual_sentence = \"To be honest, that new project is a real pain in the neck.\"\n",
        "paraphrases = generate_paraphrases(casual_sentence, num_return=4)\n",
        "\n",
        "print(f\"----------- ORIGINAL CASUAL SENTENCE -----------\\n'{casual_sentence}'\\n\")\n",
        "print(\"ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIyYbuHfti7J",
        "outputId": "601cacc9-bfa5-4d77-d185-f1d99a641b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- ORIGINAL CASUAL SENTENCE -----------\n",
            "'To be honest, that new project is a real pain in the neck.'\n",
            "\n",
            "ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\n",
            "  1. It's a real pain in the neck for that new project.\n",
            "  2. It is a real pain in the neck to have that new project.\n",
            "  3. The new project is a real pain in the neck.\n",
            "  4. It is a real pain in the neck to have a new project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4.3: Example 3 - Marketing Call-to-Action\n",
        "marketing_sentence = \"Don't miss out on our exclusive offer ‚Äì shop now to save 50%!\"\n",
        "paraphrases = generate_paraphrases(marketing_sentence, num_return=4)\n",
        "\n",
        "print(f\"----------- ORIGINAL MARKETING SENTENCE -----------\\n'{marketing_sentence}'\\n\")\n",
        "print(\"ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\")\n",
        "for i, p in enumerate(paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3klrMh-gtqS1",
        "outputId": "1f508550-6794-409e-c5f2-ee2633cc5ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- ORIGINAL MARKETING SENTENCE -----------\n",
            "'Don't miss out on our exclusive offer ‚Äì shop now to save 50%!'\n",
            "\n",
            "ü§ñ---------- PEGASUS PARAPHRASES ----------ü§ñ\n",
            "  1. Don't forget to take advantage of our exclusive offer and save 50%.\n",
            "  2. Shop now to save 50% on our exclusive offer.\n",
            "  3. Don't forget to shop now to save 50% on our exclusive offer.\n",
            "  4. Don't forget to take advantage of our exclusive offer and save 50%!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2.5: The Interactive Paraphraser Playground\n",
        "Your turn! Enter any sentence and generate creative new ways to phrase it."
      ],
      "metadata": {
        "id": "Wi1ZSh1ntwng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.5: Your Interactive Paraphraser Playground! ‚ö°Ô∏è\n",
        "#@markdown ### üëà Type your sentence and choose your settings!\n",
        "input_sentence = \"Learning new skills is essential for career growth.\" #@param {type:\"string\"}\n",
        "num_paraphrases = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "quality_vs_speed_beams = 9 #@param {type:\"slider\", min:2, max:15, step:1}\n",
        "\n",
        "# --- Run the paraphraser with your settings ---\n",
        "generated_paraphrases = generate_paraphrases(input_sentence, num_return=num_paraphrases, beams=quality_vs_speed_beams)\n",
        "\n",
        "# --- Display the results ---\n",
        "print(f\"----------- ORIGINAL SENTENCE -----------\\n'{input_sentence}'\\n\")\n",
        "print(f\"ü§ñ---------- {len(generated_paraphrases)} GENERATED PARAPHRASES (Quality: {quality_vs_speed_beams}) ----------ü§ñ\")\n",
        "for i, p in enumerate(generated_paraphrases):\n",
        "    print(f\"  {i+1}. {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNNmDBpQtx78",
        "outputId": "3abe3a43-14a4-4008-8427-43563108e9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- ORIGINAL SENTENCE -----------\n",
            "'Learning new skills is essential for career growth.'\n",
            "\n",
            "ü§ñ---------- 5 GENERATED PARAPHRASES (Quality: 10) ----------ü§ñ\n",
            "  1. It's important to learn new skills for career growth.\n",
            "  2. It's important for career growth to learn new skills.\n",
            "  3. Career growth can be achieved by learning new skills.\n",
            "  4. Career growth is dependent on learning new skills.\n",
            "  5. New skills are needed for career growth.\n"
          ]
        }
      ]
    }
  ]
}